{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "# from pycocotools.coco import COCO\n",
    "# from pycocotools.cocoeval import COCOeval\n",
    "from torchvision.ops import nms\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess\n",
    "import numpy as np\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_coef = 0\n",
    "nms_threshold = 0.5\n",
    "use_cuda = True\n",
    "gpu = 0\n",
    "use_float16 = False\n",
    "project_name = 'dl2020'\n",
    "weights_path = '/Users/mjin/Desktop/1008/Project/DeepLearning2020/saved/dl2020/dl2020_0428-124856_coef0/model/efficientdet-d0_7900.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running coco-style evaluation on project dl2020, weights /Users/mjin/Desktop/1008/Project/DeepLearning2020/saved/dl2020/dl2020_0428-124856_coef0/model/efficientdet-d0_7900.pth...\n"
     ]
    }
   ],
   "source": [
    "print(f'running coco-style evaluation on project {project_name}, weights {weights_path}...')\n",
    "\n",
    "params = yaml.safe_load(open(f'projects/{project_name}.yml'))\n",
    "obj_list = params['obj_list']\n",
    "\n",
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [\n",
    "    'CAM_FRONT_LEFT.jpeg',\n",
    "    'CAM_FRONT.jpeg',\n",
    "    'CAM_FRONT_RIGHT.jpeg',\n",
    "    'CAM_BACK_LEFT.jpeg',\n",
    "    'CAM_BACK.jpeg',\n",
    "    'CAM_BACK_RIGHT.jpeg',\n",
    "    ]\n",
    "NUM_SAMPLE_PER_SCENE = 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = range(int(params['val_set'].split(',')[0]), 130)# int(params['val_set'].split(',')[1]) + 1)\n",
    "# image_folder = os.path.join(opt.data_path, params.project_name)\n",
    "folder_path = os.path.join('datasets/', params['project_name'])\n",
    "# annotation_file = os.path.join(opt.data_path, params.project_name, opt.annotation)\n",
    "annotation_file = os.path.join('datasets/', params['project_name'], 'annotation_newfeat_2.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(128, 130)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspectaware_resize_padding(image, width, height, interpolation=None, means=None):\n",
    "    old_h, old_w, c = image.shape\n",
    "\n",
    "    # Get new wh to higher 512, lower scaled accordingly\n",
    "    if old_w > old_h:\n",
    "        new_w = width\n",
    "        new_h = int(width / old_w * old_h)\n",
    "    else:\n",
    "        new_w = int(height / old_h * old_w)\n",
    "        new_h = height\n",
    "\n",
    "    # Initialize a square 512*512\n",
    "    canvas = np.zeros((height, height, c), np.float32)\n",
    "    if means is not None:\n",
    "        canvas[...] = means\n",
    "\n",
    "    # Resize to scaled version\n",
    "    if new_w != old_w or new_h != old_h:\n",
    "        if interpolation is None:\n",
    "            image = cv2.resize(image, (new_w, new_h))\n",
    "        else:\n",
    "            image = cv2.resize(image, (new_w, new_h), interpolation=interpolation)\n",
    "\n",
    "    padding_h = height - new_h\n",
    "    padding_w = width - new_w\n",
    "\n",
    "    if c > 1:\n",
    "        # Get padded image\n",
    "        canvas[:new_h, :new_w] = image\n",
    "    else:\n",
    "        if len(image.shape) == 2:\n",
    "            canvas[:new_h, :new_w, 0] = image\n",
    "        else:\n",
    "            canvas[:new_h, :new_w] = image\n",
    "\n",
    "    return canvas, new_w, new_h, old_w, old_h, padding_w, padding_h,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dl(folder_path, val_index, max_size=512, mean=(0.406, 0.456, 0.485), std=(0.225, 0.224, 0.229)):\n",
    "    # Load original images in a list\n",
    "    ori_imgs = []\n",
    "    for scene_index in val_index:\n",
    "        scene_path = os.path.join(folder_path, 'scene_{}'.format(scene_index))\n",
    "        for sample_index in range(NUM_SAMPLE_PER_SCENE):\n",
    "            sample_path = os.path.join(scene_path, 'sample_{}'.format(sample_index))\n",
    "            \n",
    "            image_front = []\n",
    "            image_back = []\n",
    "#             images = []\n",
    "\n",
    "            for i in range(6):\n",
    "                image_path = os.path.join(sample_path, image_names[i])\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "#                 transform_dl = torchvision.transforms.ToTensor()\n",
    "#                 images.append(transform_dl(image))\n",
    "\n",
    "                if i <= 2:\n",
    "                    if len(image_front) < 1:\n",
    "                        image_front = image\n",
    "                    else:\n",
    "                        image_front = np.concatenate((image_front, image), axis=0)\n",
    "                else:\n",
    "                    if len(image_back) < 1:\n",
    "                        image_back = image\n",
    "                    else:\n",
    "                        image_back = np.concatenate((image_back, image), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "            image_cat_2 = np.concatenate((image_back, image_front), axis=1)\n",
    "#             image_cat = np.concatenate((image_front, image_back), axis=0)\n",
    "            ori_imgs.append(image_cat_2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#     ori_imgs = [cv2.imread(img_path) for img_path in image_path]\n",
    "\n",
    "    # Normalize images\n",
    "    normalized_imgs = [(img / 255 - mean) / std for img in ori_imgs]\n",
    "    \n",
    "    # Each image turn into canvas, new_w, new_h, old_w, old_h, padding_w, padding_h\n",
    "    imgs_meta = [aspectaware_resize_padding(img[..., ::-1], max_size, max_size,\n",
    "                                            means=None) for img in normalized_imgs]\n",
    "    \n",
    "    # canvas, resized padded images\n",
    "    framed_imgs = [img_meta[0] for img_meta in imgs_meta]\n",
    "    # metas\n",
    "    framed_metas = [img_meta[1:] for img_meta in imgs_meta]\n",
    "\n",
    "    return ori_imgs, framed_imgs, framed_metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs, framed_imgs, framed_metas = preprocess(folder_path, val_index, max_size=input_sizes[compound_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(framed_imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.unsqueeze(0).permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientDetBackbone(\n",
       "  (bifpn): Sequential(\n",
       "    (0): BiFPN(\n",
       "      (conv6_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv5_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv4_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv4_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv5_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv6_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv7_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p6_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p5_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p4_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p3_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p4_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p5_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p6_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p7_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (swish): MemoryEfficientSwish()\n",
       "      (p5_down_channel): Sequential(\n",
       "        (0): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p4_down_channel): Sequential(\n",
       "        (0): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(112, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p3_down_channel): Sequential(\n",
       "        (0): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p5_to_p6): Sequential(\n",
       "        (0): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool2dStaticSamePadding(\n",
       "          (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (p6_to_p7): Sequential(\n",
       "        (0): MaxPool2dStaticSamePadding(\n",
       "          (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (p4_down_channel_2): Sequential(\n",
       "        (0): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(112, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p5_down_channel_2): Sequential(\n",
       "        (0): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p6_w1_relu): ReLU()\n",
       "      (p5_w1_relu): ReLU()\n",
       "      (p4_w1_relu): ReLU()\n",
       "      (p3_w1_relu): ReLU()\n",
       "      (p4_w2_relu): ReLU()\n",
       "      (p5_w2_relu): ReLU()\n",
       "      (p6_w2_relu): ReLU()\n",
       "      (p7_w2_relu): ReLU()\n",
       "    )\n",
       "    (1): BiFPN(\n",
       "      (conv6_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv5_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv4_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv4_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv5_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv6_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv7_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p6_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p5_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p4_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p3_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p4_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p5_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p6_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p7_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (swish): MemoryEfficientSwish()\n",
       "      (p6_w1_relu): ReLU()\n",
       "      (p5_w1_relu): ReLU()\n",
       "      (p4_w1_relu): ReLU()\n",
       "      (p3_w1_relu): ReLU()\n",
       "      (p4_w2_relu): ReLU()\n",
       "      (p5_w2_relu): ReLU()\n",
       "      (p6_w2_relu): ReLU()\n",
       "      (p7_w2_relu): ReLU()\n",
       "    )\n",
       "    (2): BiFPN(\n",
       "      (conv6_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv5_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv4_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3_up): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv4_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv5_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv6_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv7_down): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (p6_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p5_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p4_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p3_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (p4_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p5_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p6_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (p7_downsample): MaxPool2dStaticSamePadding(\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (swish): MemoryEfficientSwish()\n",
       "      (p6_w1_relu): ReLU()\n",
       "      (p5_w1_relu): ReLU()\n",
       "      (p4_w1_relu): ReLU()\n",
       "      (p3_w1_relu): ReLU()\n",
       "      (p4_w2_relu): ReLU()\n",
       "      (p5_w2_relu): ReLU()\n",
       "      (p6_w2_relu): ReLU()\n",
       "      (p7_w2_relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (regressor): Regressor(\n",
       "    (conv_list): ModuleList(\n",
       "      (0): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn_list): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (header): SeparableConvBlock(\n",
       "      (depthwise_conv): Conv2dStaticSamePadding(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "      )\n",
       "      (pointwise_conv): Conv2dStaticSamePadding(\n",
       "        (conv): Conv2d(64, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (conv_list): ModuleList(\n",
       "      (0): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): SeparableConvBlock(\n",
       "        (depthwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (pointwise_conv): Conv2dStaticSamePadding(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn_list): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (header): SeparableConvBlock(\n",
       "      (depthwise_conv): Conv2dStaticSamePadding(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "      )\n",
       "      (pointwise_conv): Conv2dStaticSamePadding(\n",
       "        (conv): Conv2d(64, 135, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (anchors): Anchors()\n",
       "  (backbone_net): EfficientNet(\n",
       "    (model): EfficientNet(\n",
       "      (_conv_stem): Conv2dStaticSamePadding(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_blocks): ModuleList(\n",
       "        (0): MBConvBlock(\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=[1], groups=32, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (1): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=[2], groups=96, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (2): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (3): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=[2], groups=144, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (4): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (5): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=[2], groups=240, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (6): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (7): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (8): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=[1], groups=480, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (9): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (10): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (11): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=[2], groups=672, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (12): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (13): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (14): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (15): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=[1], groups=1152, bias=False)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "      )\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientDetBackbone(compound_coef=0, num_classes=len(obj_list),\n",
    "                                 ratios=eval(params['anchors_ratios']), scales=eval(params['anchors_scales']))\n",
    "\n",
    "model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
    "model.requires_grad_(False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, regression, classification, anchors = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "processed_image_ids = []\n",
    "\n",
    "# use to transform the output of regresser to boxes\n",
    "regressBoxes = BBoxTransform()\n",
    "# use to clip the boxes to 0, width/height\n",
    "clipBoxes = ClipBoxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(x, anchors, regression, classification, regressBoxes, clipBoxes, threshold, iou_threshold):\n",
    "    # transform regressor output to bboxes\n",
    "    transformed_anchors = regressBoxes(anchors, regression)\n",
    "    # clip the bboxes to the image size\n",
    "    transformed_anchors = clipBoxes(transformed_anchors, x)\n",
    "\n",
    "\n",
    "    scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "    scores_over_thresh = (scores > threshold)[:, :, 0]\n",
    "    out = []\n",
    "    for i in range(x.shape[0]):\n",
    "        # for image i\n",
    "\n",
    "        # If no classification score is over threshold, return none\n",
    "        if scores_over_thresh.sum() == 0:\n",
    "            out.append({\n",
    "                'rois': np.array(()),\n",
    "                'class_ids': np.array(()),\n",
    "                'scores': np.array(()),\n",
    "            })\n",
    "\n",
    "        # Filter out lines with classification score over threshold, as the classification prediction\n",
    "        classification_per = classification[i, scores_over_thresh[i, :], ...].permute(1, 0)\n",
    "\n",
    "        # The transformed anchors filtered out by cls\n",
    "        transformed_anchors_per = transformed_anchors[i, scores_over_thresh[i, :], ...]\n",
    "\n",
    "        # Real classification scores\n",
    "        scores_per = scores[i, scores_over_thresh[i, :], ...]\n",
    "\n",
    "\n",
    "        anchors_nms_idx = nms(transformed_anchors_per, scores_per[:, 0], iou_threshold=iou_threshold)\n",
    "\n",
    "        if anchors_nms_idx.shape[0] != 0:\n",
    "            scores_, classes_ = classification_per[:, anchors_nms_idx].max(dim=0)\n",
    "            boxes_ = transformed_anchors_per[anchors_nms_idx, :]\n",
    "\n",
    "            out.append({\n",
    "                'rois': boxes_.cpu().numpy(),\n",
    "                'class_ids': classes_.cpu().numpy(),\n",
    "                'scores': scores_.cpu().numpy(),\n",
    "            })\n",
    "        else:\n",
    "            out.append({\n",
    "                'rois': np.array(()),\n",
    "                'class_ids': np.array(()),\n",
    "                'scores': np.array(()),\n",
    "            })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = postprocess(x,\n",
    "                    anchors, regression, classification,\n",
    "                    regressBoxes, clipBoxes,\n",
    "                    0.1, nms_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_affine(metas: Union[float, list, tuple], preds):\n",
    "    for i in range(len(preds)):\n",
    "        if len(preds[i]['rois']) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if metas is float:\n",
    "                preds[i]['rois'][:, [0, 2]] = preds[i]['rois'][:, [0, 2]] / metas\n",
    "                preds[i]['rois'][:, [1, 3]] = preds[i]['rois'][:, [1, 3]] / metas\n",
    "            else:\n",
    "                new_w, new_h, old_w, old_h, padding_w, padding_h = metas[i]\n",
    "                preds[i]['rois'][:, [0, 2]] = preds[i]['rois'][:, [0, 2]] / (new_w / old_w)\n",
    "                preds[i]['rois'][:, [1, 3]] = preds[i]['rois'][:, [1, 3]] / (new_h / old_h)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not preds:\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(framed_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = invert_affine(framed_metas, preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = preds['scores']\n",
    "class_ids = preds['class_ids']\n",
    "rois = preds['rois']\n",
    "\n",
    "if rois.shape[0] > 0:\n",
    "    # x1,y1,x2,y2 -> x1,y1,w,h\n",
    "    rois[:, 2] -= rois[:, 0]\n",
    "    rois[:, 3] -= rois[:, 1]\n",
    "\n",
    "    bbox_score = scores\n",
    "\n",
    "    for roi_id in range(rois.shape[0]):\n",
    "        score = float(bbox_score[roi_id])\n",
    "        label = int(class_ids[roi_id])\n",
    "        box = rois[roi_id, :]\n",
    "\n",
    "        if score < 0.1:\n",
    "            break\n",
    "        image_result = {\n",
    "#             'image_id': image_id,\n",
    "            'category_id': label + 1,\n",
    "            'score': float(score),\n",
    "            'bbox': box.tolist(),\n",
    "        }\n",
    "\n",
    "        results.append(image_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dl(folder_path, val_index, model, model_name, threshold = 0.05):\n",
    "    results = pd.DataFrame({'scene_id': [],\n",
    "                    'sample_id': [],\n",
    "                    'category_id': [],\n",
    "                    'score': [],\n",
    "                    'bbox': []})\n",
    "    columns = ['scene_id', 'sample_id', 'category_id', 'score', 'bbox']\n",
    "    \n",
    "    # use to transform the output of regresser to boxes\n",
    "    regressBoxes = BBoxTransform()\n",
    "    # use to clip the boxes to 0, width/height\n",
    "    clipBoxes = ClipBoxes()\n",
    "    \n",
    "    ori_imgs, framed_imgs, framed_metas = preprocess(folder_path, val_index, max_size=input_sizes[compound_coef])\n",
    "    \n",
    "    for index in range(len(ori_imgs)):\n",
    "        scene_id = val_index[0] + index//NUM_SAMPLE_PER_SCENE\n",
    "        sample_id = index%NUM_SAMPLE_PER_SCENE\n",
    "        \n",
    "#         print(scene_id, sample_id)\n",
    "        \n",
    "        x = torch.from_numpy(framed_imgs[index])\n",
    "\n",
    "        if use_cuda:\n",
    "            x = x.cuda(gpu)\n",
    "            if use_float16:\n",
    "                x = x.half()\n",
    "            else:\n",
    "                x = x.float()\n",
    "        else:\n",
    "            x = x.float()\n",
    "        \n",
    "        x = x.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        \n",
    "#         print(x.shape)\n",
    "\n",
    "        # Run through model\n",
    "        features, regression, classification, anchors = model(x)\n",
    "        \n",
    "        preds = postprocess(x,\n",
    "                            anchors, regression, classification,\n",
    "                            regressBoxes, clipBoxes,\n",
    "                            threshold, nms_threshold)\n",
    "        \n",
    "        \n",
    "        if not preds:\n",
    "            continue\n",
    "            \n",
    "#         print(len(preds))\n",
    "\n",
    "        preds = invert_affine(framed_metas, preds)[0]\n",
    "\n",
    "        scores = preds['scores']\n",
    "        class_ids = preds['class_ids']\n",
    "        rois = preds['rois']\n",
    "\n",
    "        if rois.shape[0] > 0:\n",
    "            # x1,y1,x2,y2 -> x1,y1,w,h\n",
    "            rois[:, 2] -= rois[:, 0]\n",
    "            rois[:, 3] -= rois[:, 1]\n",
    "\n",
    "            bbox_score = scores\n",
    "\n",
    "            for roi_id in range(rois.shape[0]):\n",
    "                score = float(bbox_score[roi_id])\n",
    "                label = int(class_ids[roi_id])\n",
    "                box = rois[roi_id, :]\n",
    "\n",
    "                if score < threshold:\n",
    "                    break\n",
    "                    \n",
    "                image_result = pd.Series([scene_id, sample_id, label + 1,float(score),box.tolist()], index = columns)\n",
    "\n",
    "                results = results.append(image_result, ignore_index = True)\n",
    "                \n",
    "    results.to_csv(os.path.join(folder_path, 'evaluation_result_{}_{}_{}_{}.csv'.format(model_name, val_index[0], val_index[-1]), threshold))\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(result, annot, save_path, save = False):\n",
    "    \n",
    "    annot = pd.read_csv(annot)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'saved/dl2020/dl2020_0428-124856_coef0/model/best-efficientdet-d0_7400.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/dl2020/evaluation_result_best-efficientdet-d0_7400_128_129_0_075.csv\n",
      "saved/dl2020/dl2020_0428-124856_coef0/model/best-efficientdet-d0_7400.pth\n",
      "saved/dl2020/dl2020_0428-124856_coef0\n",
      "!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "val_index = range(int(params['val_set'].split(',')[0]), 130)  # int(params['val_set'].split(',')[1]) + 1)\n",
    "folder_path = os.path.join('datasets/', params['project_name'])\n",
    "annotation_file = os.path.join('datasets/', params['project_name'], 'annotation_newfeat_2.csv')\n",
    "save_path = os.path.join(weights_path.split('/')[0], weights_path.split('/')[1], weights_path.split('/')[2])\n",
    "model_name = weights_path.split('/')[-1].replace('.pth', '')\n",
    "\n",
    "csv_name = folder_path + '/' + 'evaluation_result_{}_{}_{}_{}'.format(model_name, val_index[0], val_index[-1], 0.075).replace('.', '_') + '.csv'\n",
    "print(csv_name)\n",
    "print(weights_path)\n",
    "print(save_path)\n",
    "\n",
    "if not os.path.exists(csv_name):\n",
    "    print('!')\n",
    "    # Initialize model\n",
    "    model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "                                 ratios=eval(params['anchors_ratios']), scales=eval(params['anchors_scales']))\n",
    "    # Load weight\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "    print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = range(int(params['val_set'].split(',')[0]), 130)# int(params['val_set'].split(',')[1]) + 1)\n",
    "folder_path = os.path.join('datasets/', params['project_name'])\n",
    "annotation_file = os.path.join('datasets/', params['project_name'], 'annotation_newfeat_2.csv')\n",
    "save_path = os.path.join(weights_path.split('/')[0], weights_path.split('/')[1], weights_path.split('/')[2])\n",
    "\n",
    "# Initialize model\n",
    "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "                             ratios=eval(params['anchors_ratios']), scales=eval(params['anchors_scales']))\n",
    "# Load weight\n",
    "model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
    "model.requires_grad_(False)\n",
    "model.eval()\n",
    "\n",
    "model_name = weights_path.split('/')[-1].replace('.pth', '')\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda(gpu)\n",
    "\n",
    "    if use_float16:\n",
    "        model.half()\n",
    "\n",
    "# Run main evaluation\n",
    "# result_df = evaluate_dl(folder_path, val_index, model, model_name, threshold = 0.075)\n",
    "\n",
    "# eval_metric(result_df, annotation_file, save_path, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['x_pred'], result_df['y_pred'], result_df['w_pred'], result_df['h_pred'] = [i[0] for i in result_df['bbox']], [i[1] for i in result_df['bbox']], [i[2] for i in result_df['bbox']], [i[3] for i in result_df['bbox']]\n",
    "\n",
    "result_df['w_original'] = result_df['w_pred']/612*80\n",
    "result_df['h_original'] = result_df['h_pred']/768*80\n",
    "\n",
    "result_df['x_ctr_original'] = result_df['x_pred']/612*80 + result_df['w_original']/2 - 40\n",
    "result_df['y_ctr_original'] = 40 - result_df['y_pred']/768*80 - result_df['h_original']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pred = result_df[result_df['scene_id'] == 129][result_df['sample_id'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 13)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = pd.read_csv(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "truth = annot[annot['scene'] == 129][annot['sample'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 31)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "fitted = pred[pred['x_ctr_original'] >= -40][pred['x_ctr_original'] <= 40][pred['y_ctr_original'] >= -40][pred['y_ctr_original'] <= 40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 13)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (3,3))\n",
    "plt.scatter(truth['center_x'], truth['center_y'])\n",
    "plt.xlim(-40, 40)\n",
    "plt.ylim(-40, 40)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (3,3))\n",
    "plt.scatter(pred['x_ctr_original'], pred['y_ctr_original'])\n",
    "plt.xlim(-40, 40)\n",
    "plt.ylim(-40, 40)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['scene_id', 'sample_id', 'category_id', 'score', 'bbox', 'x_pred',\n",
       "       'y_pred', 'w_pred', 'h_pred', 'w_original', 'h_original',\n",
       "       'x_ctr_original', 'y_ctr_original'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 2., 4., 0., 0., 2., 0., 5., 2.]),\n",
       " array([1. , 1.8, 2.6, 3.4, 4.2, 5. , 5.8, 6.6, 7.4, 8.2, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(fitted['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([26.,  0.,  0.,  2.,  0.,  0.,  1.,  0.,  0.,  1.]),\n",
       " array([2. , 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(truth['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
